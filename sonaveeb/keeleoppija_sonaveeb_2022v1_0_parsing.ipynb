{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c37f06b",
   "metadata": {},
   "source": [
    "## Õpikukorpuse vrt faili lausete süntaksianalüüs\n",
    "\n",
    "Aluseks on keeleoppija_sonaveeb_2022v1_0.vrt fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6a99a2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import estnltk\n",
    "from estnltk import Text, Layer\n",
    "from estnltk.taggers import PretokenizedTextCompoundTokensTagger, WordTagger, WhiteSpaceTokensTagger\n",
    "from estnltk_neural.taggers import StanzaSyntaxTagger\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from estnltk.converters import text_to_json, json_to_text\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "426cc332",
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = \"keeleoppija_sonaveeb_2022v1_0.vrt\"\n",
    "\n",
    "with open(infile, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "507e681d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "623219"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lines = data.split(\"\\n\")\n",
    "len(data_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e67be756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# koguda kõik dokumendid kokku\n",
    "\n",
    "document_start = False\n",
    "\n",
    "documents = []\n",
    "doc_lines = []\n",
    "\n",
    "for line in data_lines:\n",
    "    if line.startswith(\"<document\"): # dokumendi algus\n",
    "        document_start = True\n",
    "    elif line.startswith(\"</document>\"): # dokumendi lõpp\n",
    "        document_start = False\n",
    "        documents.append(doc_lines)\n",
    "        doc_lines = []\n",
    "    \n",
    "    if document_start:\n",
    "        doc_lines.append(line)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3fa3bf",
   "metadata": {},
   "source": [
    "#### WhitespaceTokensTagger + custom words layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a57763aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 35680/35680 [13:11<00:00, 45.06it/s]\n"
     ]
    }
   ],
   "source": [
    "not_word_lines = [\"<document\", \"<sentence\", \"<clause\", \"</clause>\", \"</sentence>\", \"</document>\"]\n",
    "meta_lines = [\"<document\", \"<sentence\",]\n",
    "\n",
    "# erinevate tühikuga eraldatud numbrite tuvastamiseks\n",
    "p2 = re.compile(r\"\"\"\\d+(\\s*\\d*)*\"\"\")\n",
    "\n",
    "texts_list = []\n",
    "\n",
    "tokens_tagger = WhiteSpaceTokensTagger()\n",
    "\n",
    "stanza_tagger = StanzaSyntaxTagger(input_type='morph_extended', input_morph_layer='morph_extended')\n",
    "\n",
    "for doc in tqdm(documents):\n",
    "    word_lines = []\n",
    "    meta = {}\n",
    "    for line in doc:\n",
    "        # read, millel on lauses olevad sõnad\n",
    "        if not any(ext in line for ext in not_word_lines):\n",
    "            word_lines.append(line)\n",
    "            \n",
    "        # siin koguda ka metainfo kokku \n",
    "        elif any(ext in line for ext in meta_lines):\n",
    "            line = line.replace(\"<document\", \"\").replace(\"<sentence\", \"\").strip()[:-1]\n",
    "            pairs = dict(re.findall(r'(\\w+)=\"([^\"]*)\"', line))\n",
    "            meta.update(pairs)\n",
    "            \n",
    "    # võtta ainult esimene osa, ehk sõna\n",
    "    sent_words = [row.split(\"\\t\")[0] for row in word_lines] \n",
    "\n",
    "    raw_words = [] # words kihi jaoks, sõnad nii nagu tekstis on\n",
    "    normalized_words = [] # words kihi jaoks, numbri puhul nt tühikud number keskelt eemaldatud\n",
    "    for_txt_words = [] # Text obj jaoks, ilusam, kirjavahemärgid ei ole tühikuga eraldatud\n",
    "\n",
    "    multiword_expressions = [] # multiword tokenite jaoks\n",
    "    \n",
    "    # juhuks kui on rida \"<!--g/-->\", mis tähistab, et enne järgnevat sõna pole tühikut\n",
    "    g_tag = False\n",
    "    \n",
    "    for raw_token in sent_words:\n",
    "        if raw_token not in ['<!--g/-->']:\n",
    "            if g_tag:\n",
    "                for_txt_words[-1] += raw_token\n",
    "                raw_words.append(raw_token)\n",
    "                normalized_words.append(raw_token)\n",
    "                g_tag = False\n",
    "            else:\n",
    "                # kontroll, kas on tegu numbriga, milles on tühikuid\n",
    "                res = re.search(p2, raw_token)\n",
    "                numeric_token = True if res is not None else False\n",
    "                # normaliseeritud sõnades kustutame numbrite keskelt tühikud\n",
    "                if \" \" in raw_token and numeric_token:\n",
    "                    normalized_words.append(raw_token.replace(\" \", \"\"))\n",
    "                else:\n",
    "                    normalized_words.append(raw_token)\n",
    "                    \n",
    "                raw_words.append(raw_token)\n",
    "                for_txt_words.append(raw_token)\n",
    "                    \n",
    "                if ' ' in raw_token: # kõik mis on tühikuga, ka numbrid\n",
    "                    multiword_expressions.append(raw_token)\n",
    "                \n",
    "        elif raw_token == \"<!--g/-->\": # tuleks liita eelnevale sõnale\n",
    "            g_tag = True\n",
    "\n",
    "\n",
    "    text_str = ' '.join(for_txt_words)\n",
    "    text = Text(text_str)\n",
    "\n",
    "    tokens_tagger.tag(text)\n",
    "\n",
    "    multiword_expressions = [mw.split() for mw in multiword_expressions]\n",
    "    compound_tokens_tagger = PretokenizedTextCompoundTokensTagger( multiword_units = multiword_expressions )\n",
    "    compound_tokens_tagger.tag(text)\n",
    "    \n",
    "    # minu custom layer\n",
    "    my_words = Layer(\n",
    "        name='words',\n",
    "        attributes=('normalized_form',),\n",
    "        text_object=text,\n",
    "        ambiguous=True\n",
    "    )\n",
    "\n",
    "    # lisada spanid lootuses, et start ja end saavad õiged\n",
    "    idx = 0\n",
    "    text_str = text.text\n",
    "    for raw, norm in zip(raw_words, normalized_words):\n",
    "        \n",
    "        while idx < len(text_str) and text_str[idx].isspace():\n",
    "            idx += 1\n",
    "        \n",
    "        # matchida token idx kohal\n",
    "        if not text_str.startswith(raw, idx):\n",
    "            context = text_str[idx:idx+len(raw)+3]\n",
    "            raise ValueError(\n",
    "                f\"Token alignment failed.\\n\"\n",
    "                f\"Expected: '{raw}' at {idx} in context: '{context}'\"\n",
    "            )\n",
    "        \n",
    "        start = idx\n",
    "        end = start + len(raw)\n",
    "\n",
    "        my_words.add_annotation(\n",
    "            (start, end),\n",
    "            normalized_form=norm\n",
    "        )\n",
    "\n",
    "        idx = end\n",
    "\n",
    "    # panna text-le külge\n",
    "    text.add_layer(my_words)\n",
    "    \n",
    "    #text.tag_layer('words')\n",
    "    text.tag_layer('sentences')    \n",
    "    text.tag_layer('morph_extended')\n",
    "    stanza_tagger.tag( text )\n",
    "\n",
    "    # metainfo ka juurde panna\n",
    "    text.meta = meta\n",
    "    \n",
    "    texts_list.append(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe2b802",
   "metadata": {},
   "source": [
    "## salvestada kõik tekstiobjektid ühte faili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "44b87d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_texts = []\n",
    "\n",
    "for txt in texts_list:\n",
    "    file_texts.append(text_to_json(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9304b39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"keeleoppija_sonaveeb_2022v1_0_vrt.json\", \"w\") as f:\n",
    "    json.dump(file_texts, f, ensure_ascii = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c8a212",
   "metadata": {},
   "source": [
    "#### näide sisselugemisest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "581313ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"keeleoppija_sonaveeb_2022v1_0_vrt.json\", \"r\") as f:\n",
    "    indata = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "298ac81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>stanza_syntax</td>\n",
       "      <td>id, lemma, upostag, xpostag, feats, head, deprel, deps, misc</td>\n",
       "      <td>morph_extended</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upostag</th>\n",
       "      <th>xpostag</th>\n",
       "      <th>feats</th>\n",
       "      <th>head</th>\n",
       "      <th>deprel</th>\n",
       "      <th>deps</th>\n",
       "      <th>misc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Helista</td>\n",
       "      <td>1</td>\n",
       "      <td>helistama</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "      <td>{'mod': 'mod', 'imper': 'imper', 'pres': 'pres', 'ps2': 'ps2', 'sg': 'sg', 'ps': ..., type: &lt;class 'dict'&gt;, length: 7</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kohe</td>\n",
       "      <td>2</td>\n",
       "      <td>kohe</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>advmod</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tel</td>\n",
       "      <td>3</td>\n",
       "      <td>tel</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>{'nominal': 'nominal'}</td>\n",
       "      <td>1</td>\n",
       "      <td>obl</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>641  1709</td>\n",
       "      <td>4</td>\n",
       "      <td>6411709</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>{'card': 'card', '&lt;?&gt;': '&lt;?&gt;', 'digit': 'digit'}</td>\n",
       "      <td>3</td>\n",
       "      <td>nummod</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>5</td>\n",
       "      <td>.</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>punct</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='stanza_syntax', attributes=('id', 'lemma', 'upostag', 'xpostag', 'feats', 'head', 'deprel', 'deps', 'misc'), spans=SL[Span('Helista', [{'id': 1, 'lemma': 'helistama', 'upostag': 'V', 'xpostag': 'V', 'feats': {'mod': 'mod', 'imper': 'imper', 'pres': 'pres', 'ps2': 'ps2', 'sg': 'sg', 'ps': 'ps', 'neg': 'neg'}, 'head': 0, 'deprel': 'root', 'deps': '_', 'misc': '_'}]),\n",
       "Span('kohe', [{'id': 2, 'lemma': 'kohe', 'upostag': 'D', 'xpostag': 'D', 'feats': {}, 'head': 1, 'deprel': 'advmod', 'deps': '_', 'misc': '_'}]),\n",
       "Span('tel', [{'id': 3, 'lemma': 'tel', 'upostag': 'Y', 'xpostag': 'Y', 'feats': {'nominal': 'nominal'}, 'head': 1, 'deprel': 'obl', 'deps': '_', 'misc': '_'}]),\n",
       "Span('641  1709', [{'id': 4, 'lemma': '6411709', 'upostag': 'N', 'xpostag': 'N', 'feats': {'card': 'card', '<?>': '<?>', 'digit': 'digit'}, 'head': 3, 'deprel': 'nummod', 'deps': '_', 'misc': '_'}]),\n",
       "Span('.', [{'id': 5, 'lemma': '.', 'upostag': 'Z', 'xpostag': 'Z', 'feats': {}, 'head': 1, 'deprel': 'punct', 'deps': '_', 'misc': '_'}])])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_to_text(indata[112]).stanza_syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f5f2a6",
   "metadata": {},
   "source": [
    "## salvestada iga tekstiobjekt eraldi faili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b7cbfd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i, txt in enumerate(texts_list):\n",
    "#    text_to_json(txt, file=f\"keeleoppija_sonaveeb_2022v1_0_vrt/text_{i}.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b235404c",
   "metadata": {},
   "source": [
    "#### näide sisselugemisest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7e2b801d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>stanza_syntax</td>\n",
       "      <td>id, lemma, upostag, xpostag, feats, head, deprel, deps, misc</td>\n",
       "      <td>morph_extended</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upostag</th>\n",
       "      <th>xpostag</th>\n",
       "      <th>feats</th>\n",
       "      <th>head</th>\n",
       "      <th>deprel</th>\n",
       "      <th>deps</th>\n",
       "      <th>misc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Helista</td>\n",
       "      <td>1</td>\n",
       "      <td>helistama</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "      <td>{'mod': 'mod', 'imper': 'imper', 'pres': 'pres', 'ps2': 'ps2', 'sg': 'sg', 'ps': ..., type: &lt;class 'dict'&gt;, length: 7</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kohe</td>\n",
       "      <td>2</td>\n",
       "      <td>kohe</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>advmod</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tel</td>\n",
       "      <td>3</td>\n",
       "      <td>tel</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>{'nominal': 'nominal'}</td>\n",
       "      <td>1</td>\n",
       "      <td>obl</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>641  1709</td>\n",
       "      <td>4</td>\n",
       "      <td>6411709</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>{'card': 'card', '&lt;?&gt;': '&lt;?&gt;', 'digit': 'digit'}</td>\n",
       "      <td>3</td>\n",
       "      <td>nummod</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>5</td>\n",
       "      <td>.</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>punct</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='stanza_syntax', attributes=('id', 'lemma', 'upostag', 'xpostag', 'feats', 'head', 'deprel', 'deps', 'misc'), spans=SL[Span('Helista', [{'id': 1, 'lemma': 'helistama', 'upostag': 'V', 'xpostag': 'V', 'feats': {'mod': 'mod', 'imper': 'imper', 'pres': 'pres', 'ps2': 'ps2', 'sg': 'sg', 'ps': 'ps', 'neg': 'neg'}, 'head': 0, 'deprel': 'root', 'deps': '_', 'misc': '_'}]),\n",
       "Span('kohe', [{'id': 2, 'lemma': 'kohe', 'upostag': 'D', 'xpostag': 'D', 'feats': {}, 'head': 1, 'deprel': 'advmod', 'deps': '_', 'misc': '_'}]),\n",
       "Span('tel', [{'id': 3, 'lemma': 'tel', 'upostag': 'Y', 'xpostag': 'Y', 'feats': {'nominal': 'nominal'}, 'head': 1, 'deprel': 'obl', 'deps': '_', 'misc': '_'}]),\n",
       "Span('641  1709', [{'id': 4, 'lemma': '6411709', 'upostag': 'N', 'xpostag': 'N', 'feats': {'card': 'card', '<?>': '<?>', 'digit': 'digit'}, 'head': 3, 'deprel': 'nummod', 'deps': '_', 'misc': '_'}]),\n",
       "Span('.', [{'id': 5, 'lemma': '.', 'upostag': 'Z', 'xpostag': 'Z', 'feats': {}, 'head': 1, 'deprel': 'punct', 'deps': '_', 'misc': '_'}])])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#text_import = json_to_text(file=\"keeleoppija_sonaveeb_2022v1_0_vrt/text_112.json\")\n",
    "#text_import.stanza_syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa084451",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
